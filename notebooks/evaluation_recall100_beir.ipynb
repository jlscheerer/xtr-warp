{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f159bdc-fbb1-4c78-aed3-c9ff7f3c2cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Running WARP Setup Code.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_WAIT_POLICY\"] = \"PASSIVE\"\n",
    "\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "import colbert.warp.setup\n",
    "\n",
    "from colbert.warp.config import WARPRunConfig\n",
    "from colbert.warp.searcher import WARPSearcher\n",
    "from colbert.warp.data.queries import WARPQueries\n",
    "\n",
    "DATASETS = [\"nfcorpus\", \"scifact\", \"scidocs\", \"fiqa\", \"webis-touche2020\", \"quora\"]\n",
    "\n",
    "def config_for_dataset(dataset):\n",
    "    assert dataset in DATASETS\n",
    "    # Configure WARP to use specified dataset & the unquantized model\n",
    "    optim = None\n",
    "    return WARPRunConfig(\n",
    "        nranks=4,\n",
    "        dataset=\"beir\",\n",
    "        collection=dataset,\n",
    "        datasplit=\"test\",\n",
    "        nbits=4,\n",
    "        optim=optim,\n",
    "    )\n",
    "\n",
    "def prepare_beir_dataset(dataset):\n",
    "    config = config_for_dataset(dataset=dataset)\n",
    "    queries = WARPQueries(config)\n",
    "    searcher = WARPSearcher(config)\n",
    "    return queries, searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69883399-372e-4f8c-a146-b7ef1ad90e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://arxiv.org/pdf/2304.01982 (Page 17, Table D.1)\n",
    "# Recall@100 on a subset of the BEIR benchmarks.\n",
    "xtr_paper_stats = {\n",
    "    \"One Retriever per Domain\": {\n",
    "        \"GenQ\": {\n",
    "            \"NF\": 28.0, \"SF\": 89.3, \"SD\": 33.2, \"FQ\": 61.8, \"TO\": 45.1, \"QU\": 98.9\n",
    "        },\n",
    "        \"PTR_retriever\": {\n",
    "            \"NF\": 30.6, \"SF\": 91.8, \"SD\": 41.6, \"FQ\": 76.5, \"TO\": 47.5, \"QU\": 99.6\n",
    "        }\n",
    "    },\n",
    "    \"One Retriever for All\": {\n",
    "        \"BM25\": {\n",
    "            \"NF\": 25.0, \"SF\": 90.8, \"SD\": 35.6, \"FQ\": 53.9, \"TO\": 53.8, \"QU\": 97.3\n",
    "        },\n",
    "        \"ColBERT\": {\n",
    "            \"NF\": 25.4, \"SF\": 87.8, \"SD\": 34.4, \"FQ\": 60.3, \"TO\": 43.9, \"QU\": 98.9\n",
    "        },\n",
    "        \"GTR_base\": {\n",
    "            \"NF\": 27.5, \"SF\": 87.2, \"SD\": 34.0, \"FQ\": 67.0, \"TO\": 44.3, \"QU\": 99.6\n",
    "        },\n",
    "        \"T5-ColBERT_base\": {\n",
    "            \"NF\": 27.6, \"SF\": 91.3, \"SD\": 34.2, \"FQ\": 63.0, \"TO\": 49.9, \"QU\": 97.9\n",
    "        },\n",
    "        \"XTR_base\": {\n",
    "            \"NF\": 28.0, \"SF\": 90.5, \"SD\": 34.8, \"FQ\": 63.5, \"TO\": 50.8, \"QU\": 98.9\n",
    "        },\n",
    "        \"GTR_xxl\": {\n",
    "            \"NF\": 30.0, \"SF\": 90.0, \"SD\": 36.6, \"FQ\": 78.0, \"TO\": 46.6, \"QU\": 99.7\n",
    "        },\n",
    "        \"T5-ColBERT_xxl\": {\n",
    "            \"NF\": 29.0, \"SF\": 94.6, \"SD\": 38.5, \"FQ\": 72.5, \"TO\": 50.1, \"QU\": 99.1\n",
    "        },\n",
    "        \"XTR_xxl\": {\n",
    "            \"NF\": 30.7, \"SF\": 95.0, \"SD\": 39.4, \"FQ\": 73.0, \"TO\": 52.7, \"QU\": 99.3\n",
    "        }\n",
    "    }\n",
    "}\n",
    "xxl_models = [\"GTR_xxl\", \"T5-ColBERT_xxl\", \"XTR_xxl\"]\n",
    "\n",
    "dataset_xtr_map = {\"nfcorpus\": \"NF\", \"scifact\": \"SF\", \"scidocs\": \"SD\", \"fiqa\": \"FQ\", \"webis-touche2020\": \"TO\", \"quora\": \"QU\"}\n",
    "dataset_to_name = {\"nfcorpus\": \"NFCORPUS\", \"scifact\": \"SciFact\", \"scidocs\": \"SCIDOCS\", \"fiqa\": \"FiQA-2018\",\n",
    "                   \"webis-touche2020\": \"Touche-2020\", \"quora\": \"Quora\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77472b4f-ecb4-4fc5-aacb-e0a9ef98774e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                           | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:35:29] #> Loading the queries from /lfs/1/scheerer/datasets/beir/datasets/nfcorpus/questions.test.tsv ...\n",
      "[Sep 01, 01:35:29] #> Got 323 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 01, 01:35:29] #> Loading collection...\n",
      "0M "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/future/u/scheerer/miniconda3/envs/colbert/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sep 01, 01:35:31] #> Loading buckets...\n",
      "[Sep 01, 01:35:31] #> Loading codec...\n",
      "[Sep 01, 01:35:31] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Sep 01, 01:35:31] #> Loading repacked residuals...\n",
      "[Sep 01, 01:35:31] Loading precompute_topk_centroids_cpp extension (set WARP_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Sep 01, 01:35:31] Loading decompress_centroid_embeds_strided_repacked_cpp extension (set WARP_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Sep 01, 01:35:32] Loading compute_candidate_scores_cpp extension (set WARP_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "nprobe 12 t_prime 3000\n",
      "#> Loading collection_map found in /lfs/1/scheerer/datasets/beir/datasets/nfcorpus/collection.tsv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcdc96e8c3248b9a9477823e8c68326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████████████▊                                                                                                             | 1/6 [00:38<03:10, 38.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:36:07] #> Loading the queries from /lfs/1/scheerer/datasets/beir/datasets/scifact/questions.test.tsv ...\n",
      "[Sep 01, 01:36:07] #> Got 300 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 01, 01:36:07] #> Loading collection...\n",
      "0M "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/future/u/scheerer/miniconda3/envs/colbert/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sep 01, 01:36:08] #> Loading buckets...\n",
      "[Sep 01, 01:36:08] #> Loading codec...\n",
      "[Sep 01, 01:36:08] #> Loading repacked residuals...\n",
      "nprobe 12 t_prime 5000\n",
      "#> Loading collection_map found in /lfs/1/scheerer/datasets/beir/datasets/scifact/collection.tsv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647718e1f7e74538a425347e1086ad2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████████████████▋                                                                                       | 2/6 [01:14<02:29, 37.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:36:43] #> Loading the queries from /lfs/1/scheerer/datasets/beir/datasets/scidocs/questions.test.tsv ...\n",
      "[Sep 01, 01:36:44] #> Got 1000 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 01, 01:36:44] #> Loading collection...\n",
      "0M \n",
      "[Sep 01, 01:36:45] #> Loading buckets...\n",
      "[Sep 01, 01:36:45] #> Loading codec...\n",
      "[Sep 01, 01:36:45] #> Loading repacked residuals...\n",
      "nprobe 12 t_prime 8000\n",
      "#> Loading collection_map found in /lfs/1/scheerer/datasets/beir/datasets/scidocs/collection.tsv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4346a05dd394cc3bf238b53fe652c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████████████████▌                                                                 | 3/6 [03:13<03:42, 74.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:38:42] #> Loading the queries from /lfs/1/scheerer/datasets/beir/datasets/fiqa/questions.test.tsv ...\n",
      "[Sep 01, 01:38:42] #> Got 648 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 01, 01:38:42] #> Loading collection...\n",
      "0M \n",
      "[Sep 01, 01:38:44] #> Loading buckets...\n",
      "[Sep 01, 01:38:44] #> Loading codec...\n",
      "[Sep 01, 01:38:45] #> Loading repacked residuals...\n",
      "nprobe 12 t_prime 10000\n",
      "#> Loading collection_map found in /lfs/1/scheerer/datasets/beir/datasets/fiqa/collection.tsv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1bef35505046d6a6f59f82c401a86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████████████████████████████████████▎                                           | 4/6 [04:32<02:32, 76.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:40:01] #> Loading the queries from /lfs/1/scheerer/datasets/beir/datasets/webis-touche2020/questions.test.tsv ...\n",
      "[Sep 01, 01:40:01] #> Got 49 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 01, 01:40:01] #> Loading collection...\n",
      "0M \n",
      "[Sep 01, 01:40:05] #> Loading buckets...\n",
      "[Sep 01, 01:40:05] #> Loading codec...\n",
      "[Sep 01, 01:40:08] #> Loading repacked residuals...\n",
      "nprobe 18 t_prime 50000\n",
      "#> Loading collection_map found in /lfs/1/scheerer/datasets/beir/datasets/webis-touche2020/collection.tsv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77bbf37298042259c58684a1e52a735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/382545 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 5/6 [04:56<00:57, 57.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:40:25] #> Loading the queries from /lfs/1/scheerer/datasets/beir/datasets/quora/questions.test.tsv ...\n",
      "[Sep 01, 01:40:25] #> Got 10000 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 01, 01:40:25] #> Loading collection...\n",
      "0M \n",
      "[Sep 01, 01:40:27] #> Loading buckets...\n",
      "[Sep 01, 01:40:27] #> Loading codec...\n",
      "[Sep 01, 01:40:27] #> Loading repacked residuals...\n",
      "nprobe 12 t_prime 10000\n",
      "#> Loading collection_map found in /lfs/1/scheerer/datasets/beir/datasets/quora/collection.tsv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b27ba683154d139c76a7b28038ed05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/522931 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [25:31<00:00, 255.31s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "metrics = dict()\n",
    "for dataset in tqdm(DATASETS):\n",
    "    queries, searcher = prepare_beir_dataset(dataset=dataset)\n",
    "    rankings = searcher.search_all(queries, k=100, batched=False, show_progress=False)\n",
    "    metrics[dataset] = rankings.evaluate(queries.qrels, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa457132-def2-4f97-9387-7e13cd42836e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   NFCORPUS    SciFact    SCIDOCS    FiQA-2018    Touche-2020    Quora    Avg.\n",
      "---------------  ----------  ---------  ---------  -----------  -------------  -------  ------\n",
      "BM25                   25.0       90.8       35.6         53.9           53.8     97.3    59.4\n",
      "ColBERT                25.4       87.8       34.4         60.3           43.9     98.9    58.4\n",
      "GTR_base               27.5       87.2       34.0         67.0           44.3     99.6    59.9\n",
      "T5-ColBERT_base        27.6       91.3       34.2         63.0           49.9     97.9    60.6\n",
      "XTR_base               28.0       90.5       34.8         63.5           50.8     98.9    61.1\n",
      "XTR_base / WARP        28.3       92.4       36.4         60.8           51.1     98.7    61.3\n",
      "---------------  ----------  ---------  ---------  -----------  -------------  -------  ------\n",
      "GTR_xxl                30.0       90.0       36.6         78.0           46.6     99.7    63.5\n",
      "T5-ColBERT_xxl         29.0       94.6       38.5         72.5           50.1     99.1    64.0\n",
      "XTR_xxl                30.7       95.0       39.4         73.0           52.7     99.3    65.0\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate, SEPARATING_LINE\n",
    "\n",
    "headers = [\"\"] + [dataset_to_name[dataset] for dataset in DATASETS] + [\"Avg.\"]\n",
    "\n",
    "def append_model_metrics(data, model_names):\n",
    "    for model_name in model_names:\n",
    "        results = xtr_paper_stats[\"One Retriever for All\"][model_name]\n",
    "        scores = [results[dataset_xtr_map[dataset]] for dataset in DATASETS]\n",
    "        avg = round(sum(scores) / len(DATASETS), 1)\n",
    "        data.append([model_name] + scores + [avg])\n",
    "\n",
    "data = []\n",
    "append_model_metrics(data, [x for x in xtr_paper_stats[\"One Retriever for All\"].keys() if x not in xxl_models])\n",
    "warp_scores = [round(metrics[dataset][\"recall@100\"] * 100, 1) for dataset in DATASETS]\n",
    "warp_avg = round(sum(warp_scores) / len(DATASETS), 1)\n",
    "data.append(\n",
    "    [\"XTR_base / WARP\"] + warp_scores + [warp_avg]\n",
    ")\n",
    "data.append([SEPARATING_LINE])\n",
    "append_model_metrics(data, xxl_models)\n",
    "\n",
    "print(tabulate(data, headers, floatfmt=\".1f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
