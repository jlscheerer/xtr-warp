{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f159bdc-fbb1-4c78-aed3-c9ff7f3c2cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Running WARP Setup Code.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_WAIT_POLICY\"] = \"PASSIVE\"\n",
    "\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "import colbert.warp.setup\n",
    "\n",
    "from colbert.warp.config import WARPRunConfig\n",
    "from colbert.warp.searcher import WARPSearcher\n",
    "from colbert.warp.data.queries import WARPQueries\n",
    "\n",
    "DATASETS = [\"lifestyle\", \"writing\", \"recreation\", \"technology\", \"science\", \"pooled\"]\n",
    "\n",
    "def config_for_dataset(dataset):\n",
    "    assert dataset in DATASETS\n",
    "    # Configure WARP to use specified dataset & the unquantized model\n",
    "    optim = None\n",
    "    return WARPRunConfig(\n",
    "        nranks=4,\n",
    "        dataset=\"lotte\",\n",
    "        collection=dataset,\n",
    "        type_=\"search\",\n",
    "        datasplit=\"test\",\n",
    "        nbits=4,\n",
    "        optim=optim,\n",
    "    )\n",
    "\n",
    "def prepare_lotte_dataset(dataset):\n",
    "    config = config_for_dataset(dataset=dataset)\n",
    "    queries = WARPQueries(config)\n",
    "    searcher = WARPSearcher(config)\n",
    "    return queries, searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69883399-372e-4f8c-a146-b7ef1ad90e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://arxiv.org/pdf/2304.01982 (Page 6, Table 2)\n",
    "# Success@5 on the LoTTE Search benchmarks.\n",
    "\n",
    "xtr_paper_stats = {\n",
    "    \"BM25\": {\n",
    "        \"Writing\": 60.3, \"Recreation\": 56.5, \"Science\": 32.7, \"Technology\": 41.8, \"Lifestyle\": 63.8, \"Pooled\": 48.3\n",
    "    },\n",
    "    \"ColBERT\": {\n",
    "        \"Writing\": 74.7, \"Recreation\": 68.5, \"Science\": 53.6, \"Technology\": 61.9, \"Lifestyle\": 80.2, \"Pooled\": 67.3\n",
    "    },\n",
    "    \"GTR_base\": {\n",
    "        \"Writing\": 74.1, \"Recreation\": 65.7, \"Science\": 49.8, \"Technology\": 58.1, \"Lifestyle\": 82.0, \"Pooled\": 65.0\n",
    "    },\n",
    "    \"XTR_base\": {\n",
    "        \"Writing\": 77.0, \"Recreation\": 69.4, \"Science\": 54.9, \"Technology\": 63.2, \"Lifestyle\": 82.1, \"Pooled\": 69.0\n",
    "    },\n",
    "    \"Splade_v2\": {\n",
    "        \"Writing\": 77.1, \"Recreation\": 69.0, \"Science\": 55.4, \"Technology\": 62.4, \"Lifestyle\": 82.3, \"Pooled\": 68.9\n",
    "    },\n",
    "    \"ColBERT_v2\": {\n",
    "        \"Writing\": 80.1, \"Recreation\": 72.3, \"Science\": 56.7, \"Technology\": 66.1, \"Lifestyle\": 84.7, \"Pooled\": 71.6\n",
    "    },\n",
    "    \"GTR_xxl\": {\n",
    "        \"Writing\": 83.9, \"Recreation\": 78.0, \"Science\": 60.0, \"Technology\": 69.5, \"Lifestyle\": 87.4, \"Pooled\": 76.0\n",
    "    },\n",
    "    \"XTR_xxl\": {\n",
    "        \"Writing\": 83.3, \"Recreation\": 79.3, \"Science\": 60.8, \"Technology\": 73.7, \"Lifestyle\": 89.1, \"Pooled\": 77.3\n",
    "    }\n",
    "}\n",
    "\n",
    "cross_encoder_hard_neg_models = [\"Splade_v2\", \"ColBERT_v2\"]\n",
    "xxl_models = [\"GTR_xxl\", \"XTR_xxl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d564ab67-7d65-45ac-8e18-fedd9c53d9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                           | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:45:36] #> Loading the queries from /lfs/1/scheerer/datasets/lotte/lotte/lifestyle/test/questions.search.tsv ...\n",
      "[Sep 01, 01:45:36] #> Got 661 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 01, 01:45:36] #> Loading collection...\n",
      "0M \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/future/u/scheerer/miniconda3/envs/colbert/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:45:39] #> Loading buckets...\n",
      "[Sep 01, 01:45:39] #> Loading codec...\n",
      "[Sep 01, 01:45:39] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Sep 01, 01:45:40] #> Loading repacked residuals...\n",
      "[Sep 01, 01:45:40] Loading precompute_topk_centroids_cpp extension (set WARP_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Sep 01, 01:45:41] Loading decompress_centroid_embeds_strided_repacked_cpp extension (set WARP_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Sep 01, 01:45:41] Loading compute_candidate_scores_cpp extension (set WARP_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "nprobe 12 t_prime 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████████████▊                                                                                                             | 1/6 [01:25<07:05, 85.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:47:01] #> Loading the queries from /lfs/1/scheerer/datasets/lotte/lotte/writing/test/questions.search.tsv ...\n",
      "[Sep 01, 01:47:01] #> Got 1071 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 01, 01:47:01] #> Loading collection...\n",
      "0M \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/future/u/scheerer/miniconda3/envs/colbert/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:47:04] #> Loading buckets...\n",
      "[Sep 01, 01:47:04] #> Loading codec...\n",
      "[Sep 01, 01:47:05] #> Loading repacked residuals...\n",
      "nprobe 12 t_prime 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████████████████▎                                                                                      | 2/6 [03:37<07:32, 113.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:49:14] #> Loading the queries from /lfs/1/scheerer/datasets/lotte/lotte/recreation/test/questions.search.tsv ...\n",
      "[Sep 01, 01:49:14] #> Got 924 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 01, 01:49:14] #> Loading collection...\n",
      "0M \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/future/u/scheerer/miniconda3/envs/colbert/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:49:16] #> Loading buckets...\n",
      "[Sep 01, 01:49:16] #> Loading codec...\n",
      "[Sep 01, 01:49:17] #> Loading repacked residuals...\n",
      "nprobe 12 t_prime 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████████████████                                                                 | 3/6 [05:36<05:46, 115.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:51:12] #> Loading the queries from /lfs/1/scheerer/datasets/lotte/lotte/technology/test/questions.search.tsv ...\n",
      "[Sep 01, 01:51:12] #> Got 596 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 01, 01:51:12] #> Loading collection...\n",
      "0M \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/future/u/scheerer/miniconda3/envs/colbert/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:51:17] #> Loading buckets...\n",
      "[Sep 01, 01:51:17] #> Loading codec...\n",
      "[Sep 01, 01:51:21] #> Loading repacked residuals...\n",
      "nprobe 18 t_prime 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████████████████████████████████████▋                                           | 4/6 [07:38<03:56, 118.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:53:15] #> Loading the queries from /lfs/1/scheerer/datasets/lotte/lotte/science/test/questions.search.tsv ...\n",
      "[Sep 01, 01:53:15] #> Got 617 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 01, 01:53:15] #> Loading collection...\n",
      "0M 1M \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/future/u/scheerer/miniconda3/envs/colbert/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:53:25] #> Loading buckets...\n",
      "[Sep 01, 01:53:25] #> Loading codec...\n",
      "[Sep 01, 01:53:41] #> Loading repacked residuals...\n",
      "nprobe 24 t_prime 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 5/6 [11:04<02:29, 149.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:56:41] #> Loading the queries from /lfs/1/scheerer/datasets/lotte/lotte/pooled/test/questions.search.tsv ...\n",
      "[Sep 01, 01:56:41] #> Got 3869 queries. All QIDs are unique.\n",
      "\n",
      "[Sep 01, 01:56:41] #> Loading collection...\n",
      "0M 1M 2M \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/future/u/scheerer/miniconda3/envs/colbert/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 01, 01:56:56] #> Loading buckets...\n",
      "[Sep 01, 01:56:56] #> Loading codec...\n",
      "[Sep 01, 01:57:19] #> Loading repacked residuals...\n",
      "nprobe 24 t_prime 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [33:12<00:00, 332.06s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "metrics = dict()\n",
    "for dataset in tqdm(DATASETS):\n",
    "    queries, searcher = prepare_lotte_dataset(dataset=dataset)\n",
    "    rankings = searcher.search_all(queries, k=5, batched=False, show_progress=False)\n",
    "    metrics[dataset] = rankings.evaluate(queries.qrels, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceabf36a-11fa-45e9-a424-b311681808a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lifestyle': {'provenance': {'query_type': 'search', 'dataset': 'lifestyle'},\n",
       "  'metrics': {'Success@5': 0.8229954614220878}},\n",
       " 'writing': {'provenance': {'query_type': 'search', 'dataset': 'writing'},\n",
       "  'metrics': {'Success@5': 0.7684407096171803}},\n",
       " 'recreation': {'provenance': {'query_type': 'search',\n",
       "   'dataset': 'recreation'},\n",
       "  'metrics': {'Success@5': 0.6904761904761905}},\n",
       " 'technology': {'provenance': {'query_type': 'search',\n",
       "   'dataset': 'technology'},\n",
       "  'metrics': {'Success@5': 0.6409395973154363}},\n",
       " 'science': {'provenance': {'query_type': 'search', 'dataset': 'science'},\n",
       "  'metrics': {'Success@5': 0.5607779578606159}},\n",
       " 'pooled': {'provenance': {'query_type': 'search', 'dataset': 'pooled'},\n",
       "  'metrics': {'Success@5': 0.6805376066166968}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4204de1e-e945-426c-bcf3-a5c5acc9d631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lifestyle 82.3\n",
      "writing 76.8\n",
      "recreation 69.0\n",
      "technology 64.1\n",
      "science 56.1\n",
      "pooled 68.1\n"
     ]
    }
   ],
   "source": [
    "for dataset, results in metrics.items():\n",
    "    result_success5 = round(results[\"metrics\"][\"Success@5\"] * 100, 1)\n",
    "    print(dataset, result_success5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa457132-def2-4f97-9387-7e13cd42836e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Lifestyle    Writing    Recreation    Technology    Science    Pooled    Avg.\n",
      "---------------  -----------  ---------  ------------  ------------  ---------  --------  ------\n",
      "BM25                    63.8       60.3          56.5          41.8       32.7      48.3    50.6\n",
      "ColBERT                 80.2       74.7          68.5          61.9       53.6      67.3    67.7\n",
      "GTR_base                82.0       74.1          65.7          58.1       49.8      65.0    65.8\n",
      "XTR_base                82.1       77.0          69.4          63.2       54.9      69.0    69.3\n",
      "XTR_base / WARP         82.3       76.8          69.0          64.1       56.1      68.1    69.4\n",
      "---------------  -----------  ---------  ------------  ------------  ---------  --------  ------\n",
      "Splade_v2               82.3       77.1          69.0          62.4       55.4      68.9    69.2\n",
      "ColBERT_v2              84.7       80.1          72.3          66.1       56.7      71.6    71.9\n",
      "---------------  -----------  ---------  ------------  ------------  ---------  --------  ------\n",
      "GTR_xxl                 87.4       83.9          78.0          69.5       60.0      76.0    75.8\n",
      "XTR_xxl                 89.1       83.3          79.3          73.7       60.8      77.3    77.2\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate, SEPARATING_LINE\n",
    "\n",
    "headers = [\"\"] + [dataset.title() for dataset in DATASETS] + [\"Avg.\"]\n",
    "\n",
    "def append_model_metrics(data, model_names):\n",
    "    for model_name in model_names:\n",
    "        results = xtr_paper_stats[model_name]\n",
    "        scores = [results[dataset.title()] for dataset in DATASETS]\n",
    "        avg = round(sum(scores) / len(DATASETS), 1)\n",
    "        data.append([model_name] + scores + [avg])\n",
    "\n",
    "data = []\n",
    "append_model_metrics(data, [x for x in xtr_paper_stats.keys() if x not in cross_encoder_hard_neg_models + xxl_models])\n",
    "warp_scores = [round(metrics[dataset][\"metrics\"][\"Success@5\"] * 100, 1) for dataset in DATASETS]\n",
    "warp_avg = round(sum(warp_scores) / len(DATASETS), 1)\n",
    "data.append(\n",
    "    [\"XTR_base / WARP\"] + warp_scores + [warp_avg]\n",
    ")\n",
    "data.append([SEPARATING_LINE])\n",
    "append_model_metrics(data, cross_encoder_hard_neg_models)\n",
    "data.append([SEPARATING_LINE])\n",
    "append_model_metrics(data, xxl_models)\n",
    "\n",
    "print(tabulate(data, headers, floatfmt=\".1f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
